{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826f0d43-254f-48b2-ab37-67e91a9af94b",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6e903-6ade-4fa8-8f1a-e4b64c150d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.csv as csv\n",
    "import pyarrow.parquet as pq \n",
    "import glob\n",
    "import os\n",
    "import pyarrow as pa\n",
    "from pyarrow import parquet \n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_point, theme, scale_y_reverse, scale_color_identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ba4eb-98fe-45a9-927a-2b3cd37a2628",
   "metadata": {},
   "source": [
    "## General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f433a-d163-4d50-ac83-5ac6410a0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinate parser to fix formatting inconsistencies\n",
    "def parse_coordinate(coordinate):\n",
    "    if len(coordinate) < 20:\n",
    "        return coordinate\n",
    "    else:\n",
    "        coordinate = coordinate.replace(\" \", \"\").replace(\":\", \",\").split(\",\")\n",
    "        x = coordinate[1]\n",
    "        y = coordinate[3]\n",
    "        return f\"{x}\" + \",\" + f\"{y}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48fea01-d9f1-4e53-865d-89b179deab27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4c086a5-3534-46b4-9ee5-6b339536d901",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tony Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec17a30-e564-4ec0-8375-c3e18891c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data1 = pd.read_csv(r\"C:\\Users\\tony9\\Downloads\\merged-csv-files1.csv\")\n",
    "data2 = pd.read_csv(\"C:\\\\Users\\\\tony9\\\\OneDrive\\\\Documents\\\\merged-csv-files2.csv\")\n",
    "data3 = pd.read_csv(\"C:\\\\Users\\\\tony9\\\\OneDrive\\\\Documents\\\\merged-csv-files3.csv\")\n",
    "data4 = pd.read_csv(\"C:\\\\Users\\\\tony9\\\\OneDrive\\\\Documents\\\\merged-csv-files4.csv\")\n",
    "\n",
    "data1 = data1.dropna()\n",
    "data = data1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8500f46-ab88-42a7-bcc1-613f018df0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time from string to datetime\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data['date'] = data['timestamp'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f3116-11d2-4a33-b5a3-333ae00cac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop coordinate and pixel color\n",
    "new_data = data.drop(['coordinate', 'pixel_color'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca776ed-afbe-4177-b7aa-5025240b5d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_frequency = data.groupby('user').size().reset_index(name='frequency')\n",
    "user_frequency.to_csv(\"C:/Users/tony9/Downloads/filename1.csv\", index=False)\n",
    "\n",
    "user_frequency2 = data2.groupby('user').size().reset_index(name='frequency')\n",
    "user_frequency2.to_csv(\"C:/Users/tony9/Downloads/filename.csv\", index=False)\n",
    "\n",
    "user_frequency3 = data3.groupby('user').size().reset_index(name='frequency')\n",
    "user_frequency3.to_csv(\"C:/Users/tony9/Downloads/filename3.csv\", index=False)\n",
    "\n",
    "user_frequency4 = data4.groupby('user').size().reset_index(name='frequency')\n",
    "user_frequency4.to_csv(\"C:/Users/tony9/Downloads/filename4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8820c0-69c5-4c71-833e-edba1f189811",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_user_frequency4 = user_frequency4.sort_values(by='frequency', ascending=False)\n",
    "sorted_user_frequency4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289782e-7bf4-4929-9153-bb56871930e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([user_frequency, user_frequency2, user_frequency3, user_frequency4])\n",
    "summed_df = merged_df.groupby('user', as_index=False).sum()\n",
    "summed_df.to_csv(\"summed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8d8ef-e8c8-482c-81c1-1830b9e7e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\tony9\\\\Downloads\\\\rplacemergedcondensed\"\n",
    "\n",
    "file_names = ['filename.csv', 'filename1.csv', 'filename3.csv', 'filename4.csv']\n",
    "\n",
    "df_list = []\n",
    "for file in file_names:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "merged_df = pd.concat(df_list)\n",
    "\n",
    "grouped_df = merged_df.groupby('user', as_index=False).sum()\n",
    "\n",
    "output_file = os.path.join(folder_path, \"merged_output.csv\")\n",
    "grouped_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Merged file created at:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beaeee5-d759-43a0-ba13-2e3608f716c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_condensed = pd.read_csv(r\"C:\\Users\\tony9\\Downloads\\rplacemergedcondensed\\merged_output.csv\")\n",
    "grouped_df = merged_condensed.groupby('user')['frequency'].sum().reset_index()\n",
    "grouped_df.to_csv(\"C:/Users/tony9/Downloads/filename4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2760e272-c1d7-48b4-b20e-190c62876ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from plotnine import *\n",
    "\n",
    "# Testing code for loop\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\tony9\\Downloads\\2023_place_canvas_history-000000000000.csv\")\n",
    "\n",
    "data = data.drop(['coordinate', 'pixel_color'], axis=1)\n",
    "\n",
    "def parse_timestamp(timestamp): # Check if the timestamp has microsecond part \n",
    "    if '.' in timestamp: \n",
    "        return datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S.%f %Z\") \n",
    "    else: \n",
    "        return datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S %Z\") \n",
    "    \n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"].apply(parse_timestamp))\n",
    "\n",
    "data[\"day\"] = data[\"timestamp\"].dt.day\n",
    "data[\"hour\"] = data[\"timestamp\"].dt.hour\n",
    "\n",
    "data = data.drop(['timestamp'], axis=1)\n",
    "\n",
    "\n",
    "unique_users_count = data.groupby(['day', 'hour'])['user'].nunique()\n",
    "\n",
    "unique_users_day_hour = unique_users_count.reset_index()\n",
    "\n",
    "# Rename the column for clarity\n",
    "unique_users_day_hour.rename(columns={'user': 'unique_users_count'}, inplace=True)\n",
    "\n",
    "unique_users_day_hour.to_csv(r\"C:\\Users\\tony9\\Downloads\\rplace1.csv\", index=False)\n",
    "\n",
    "# Running loop on all data\n",
    "\n",
    "file_paths = [f\"C:\\\\Users\\\\tony9\\\\Downloads\\\\2023_place_canvas_history-{i:012d}.csv\" for i in range(52)]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# Process each file and aggregate data\n",
    "for file_path in file_paths:\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        data = data.drop(['coordinate', 'pixel_color'], axis=1)\n",
    "        data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"].apply(parse_timestamp))\n",
    "        data[\"day\"] = data[\"timestamp\"].dt.day\n",
    "        data[\"hour\"] = data[\"timestamp\"].dt.hour\n",
    "        data = data.drop(['timestamp'], axis=1)\n",
    "        unique_users_count = data.groupby(['day', 'hour'])['user'].nunique().reset_index()\n",
    "        unique_users_count.rename(columns={'user': 'unique_users_count'}, inplace=True)\n",
    "        all_data.append(unique_users_count)\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "combined_data = pd.concat(all_data)\n",
    "\n",
    "final_data = combined_data.groupby(['day', 'hour'])['unique_users_count'].sum().reset_index()\n",
    "\n",
    "final_data.to_csv(r\"C:\\Users\\tony9\\Downloads\\aggregated_data.csv\", index=False)\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\tony9\\Downloads\\aggregated_data.csv\")\n",
    "\n",
    "# Correcting the code to create a bar chart for average daily users using plotnine\n",
    "plot = (ggplot(data=data, mapping=aes(x='day', y='unique_users_count'))\n",
    "                                       + geom_bar(stat=\"identity\", fill=\"skyblue\")\n",
    "                                       + labs(title=\"Average Daily Users (Bar Chart)\", x=\"Day\", y=\"Average Users Count\")\n",
    "                                       + ylab(\"Daily Unique Users\")\n",
    "                                       + theme(figure_size=(12, 6))\n",
    "                                      )\n",
    "\n",
    "plot\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\tony9\\Downloads\\2023_place_canvas_history-000000000000.csv\")\n",
    "\n",
    "data = data.drop(['coordinate', 'user'], axis=1)\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"].apply(parse_timestamp))\n",
    "data[\"day\"] = data[\"timestamp\"].dt.day\n",
    "data[\"hour\"] = data[\"timestamp\"].dt.hour\n",
    "data = data.drop(['timestamp'], axis=1)\n",
    "\n",
    "# Calculate the total pixels placed for each hour and day combo\n",
    "total_pixels_placed = data.groupby(['day', 'hour']).size().reset_index()\n",
    "total_pixels_placed.rename(columns={0: 'total_pixels_placed'}, inplace=True)\n",
    "\n",
    "total_pixels_placed.to_csv(r\"C:\\Users\\tony9\\Downloads\\rplace69.csv\", index=False)\n",
    "\n",
    "# Running loop on all data\n",
    "file_paths = [f\"C:\\\\Users\\\\tony9\\\\Downloads\\\\2023_place_canvas_history-{i:012d}.csv\" for i in range(52)]\n",
    "all_data = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        data = data.drop(['coordinate', 'user'], axis=1)\n",
    "        data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"].apply(parse_timestamp))\n",
    "        data[\"day\"] = data[\"timestamp\"].dt.day\n",
    "        data[\"hour\"] = data[\"timestamp\"].dt.hour\n",
    "        data = data.drop(['timestamp'], axis=1)\n",
    "        total_pixels_placed = data.groupby(['day', 'hour']).size().reset_index()\n",
    "        total_pixels_placed.rename(columns={0: 'total_pixels_placed'}, inplace=True)\n",
    "        all_data.append(total_pixels_placed)\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Combine all data\n",
    "combined_data = pd.concat(all_data)\n",
    "\n",
    "final_data = combined_data.groupby(['day', 'hour'])['total_pixels_placed'].sum().reset_index()\n",
    "\n",
    "final_data.to_csv(r\"C:\\Users\\tony9\\Downloads\\aggregated_data200.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351148f-b1d2-4649-b572-5fc46f7579c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\tony9\\Downloads\\aggregated_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cde88c-d17f-416a-b2cd-a26ca92f019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = (\n",
    "    ggplot(data, aes(x='factor(day)', y='unique_users_count')) +\n",
    "    geom_boxplot(fill = 'skyblue') +\n",
    "    theme(\n",
    "        axis_text_x=element_text(angle=90),\n",
    "        figure_size=(10, 6)\n",
    "    ) +\n",
    "    labs(\n",
    "        title='Distribution of Unique Users by Day',\n",
    "        x='Day',\n",
    "        y='Unique Users'\n",
    "    ) +\n",
    "    theme_minimal()\n",
    ")\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1309ddf9-c6ac-4ac4-8b88-d4ccea105316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by hour and calculating the average number of unique users per hour\n",
    "hourly_average = data.groupby('hour')['unique_users_count'].mean().reset_index()\n",
    "\n",
    "# Creating a bar plot using ggplot from plotnine\n",
    "plot = (\n",
    "    ggplot(hourly_average, aes(x='hour', y='unique_users_count')) +\n",
    "    geom_bar(stat='identity', fill='skyblue') +\n",
    "    theme(axis_text_x=element_text(angle=90), figure_size=(10, 6)) +\n",
    "    labs(\n",
    "        title='Average Number of Users by Hour',\n",
    "        x='Hour',\n",
    "        y='Unique Users'\n",
    "    )\n",
    "    + theme_minimal()\n",
    ")\n",
    "\n",
    "# Displaying the plot\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276ddc0-9c5f-4735-ac65-e8eb99a6f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_200 = pd.read_csv(r\"C:\\Users\\tony9\\Downloads\\aggregated_data200.csv\")\n",
    "merged_data = pd.merge(data, data_200, on=['day', 'hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9600679-0f4b-46ee-b360-4804ce1698c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = (\n",
    "    ggplot(merged_data, aes(x='unique_users_count', y='total_pixels_placed')) +\n",
    "    geom_point(color='blue', alpha=0.5) +\n",
    "    labs(title='Scatter Plot of Unique Users vs Total Pixels Placed',\n",
    "         x='Unique Users Count',\n",
    "         y='Total Pixels Placed') +\n",
    "    theme_minimal() +\n",
    "    theme(figure_size=(10, 6))\n",
    ")\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03f2c4b-a77b-40ab-814b-d6fab3fb573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_average = data_200.groupby('hour')['total_pixels_placed'].mean().reset_index()\n",
    "\n",
    "plot = (\n",
    "    ggplot(hourly_average, aes(x='factor(hour)', y='total_pixels_placed')) +\n",
    "    geom_bar(stat='identity', fill='skyblue') +  # Using geom_bar for bar chart\n",
    "    theme(axis_text_x=element_text(angle=90), figure_size=(10, 6)) +\n",
    "    labs(\n",
    "        title='Average Tile Placements by Hour',\n",
    "        x='Hour',\n",
    "        y='Average Placements'\n",
    "    )\n",
    "    + theme_minimal()\n",
    ")\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c6e8a-b2c2-4355-9d87-de7a8bb2d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this data comes from previously merged data files in above code. Only unique users & respective frequency columns\n",
    "data = pd.read_csv(r\"C:\\Users\\tony9\\Downloads\\rplacemergedcondensed\\merged_output.csv\")\n",
    "\n",
    "count_high_frequency = data[data['frequency'] >= 5700].shape[0]\n",
    "# finding max frequency\n",
    "print(\"Count of users with at least 21 in frequency:\", count_high_frequency)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = [0, 5, 10, 25, 50, 100, 200,500, 1000, 5700]\n",
    "labels = ['0-5', '6-10','11-25', '26-50', '51-100', '101-200', '201-500','501-1000','1001-5700']\n",
    "data['frequency_range'] = pd.cut(data['frequency'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Count users in each range\n",
    "frequency_distribution = data['frequency_range'].value_counts()\n",
    "\n",
    "# adjusting pie chart output\n",
    "explode_values = [0.05] * len(frequency_distribution)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(frequency_distribution, labels=None, autopct='%1.1f%%', pctdistance=0.85, explode=explode_values)\n",
    "plt.legend(frequency_distribution.index, title=\"Slice Numbers\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "plt.title('Pixel Frequency', fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89209874-d215-4d25-b83c-caa35ebae3a3",
   "metadata": {},
   "source": [
    "## Jake Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24e60b1-4941-4af9-aa65-1de580f9acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('merged-csv-condensed-files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1293b-bf20-4790-8e4f-cf29f325eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "len(data[data['frequency'] == 1])/len(data)\n",
    "len(data[data['frequency'] == 20])/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49a5c8-ca05-412a-b224-c1f00167e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average number of pixels placed\n",
    "data['frequency'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10557ce-c57c-4edc-864f-fe3cec5249ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loop to find the proportion of users who placed a certain amount of pixels. Only did the first 20 for simplicity's sake.\n",
    "df = pd.DataFrame(columns=['Frequency', 'Proportion'])\n",
    "for i in np.arange(1, 21):\n",
    "    x = len(data[data['frequency'] == i])/len(data)\n",
    "    df = df.append({'Frequency': i, 'Proportion': x}, ignore_index=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45010a87-c10b-408d-b48f-c4b96fb169fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"props.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef62265-c764-4893-8500-1fdcd5253b92",
   "metadata": {},
   "source": [
    "## Tuukka Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b7936-56a3-4197-8727-802ad0e4b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pl.scan_parquet('<REPLACE WITH FILE PATH>', n_rows = 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228d502-3760-496f-a9e7-26deba908dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Coordinates\n",
    "data1 = data1.with_columns(\n",
    "    pl.col('coordinate').map_elements(parse_coordinate, return_dtype=pl.Object)\n",
    ")\n",
    "data1 = data1.with_columns([\n",
    "    pl.col('coordinate').map_elements(lambda x: int(x.split(\",\")[0]), return_dtype=pl.Int32).alias('x'),\n",
    "    pl.col('coordinate').map_elements(lambda x: int(x.split(\",\")[1]), return_dtype=pl.Int32).alias('y')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b0692d-1f68-436f-85c8-885c35949d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Polars stuff that Tuukka did\n",
    "user_counts = data1.select(\"user\").group_by(\"user\").agg(pl.col('user').count().alias('count')).sort('count', descending = True)\n",
    "user_counts = user_counts.with_columns(pl.col('count').cast(int))\n",
    "\n",
    "user_counts = user_counts.filter(pl.col('count') > 20)\n",
    "\n",
    "count_list = user_counts.select('user').collect(streaming = True)\n",
    "\n",
    "data1 = data1.filter(pl.col('user').is_in(count_list))\n",
    "\n",
    "user_counts.select(pl.len()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff3af0-064f-4707-9149-d32fe43e21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some more Polars stuff that Tuukka did\n",
    "sorted_ = data1.sort(pl.col(['user', 'timestamp']))\n",
    "\n",
    "sorted_ = sorted_.with_columns(pl.col('timestamp').str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S%.f %Z\").cast(pl.Datetime, strict = False))\n",
    "\n",
    "sorted_ = sorted_.group_by('user').agg(pl.col('timestamp').diff(null_behavior = \"drop\").alias('diff'))\n",
    "\n",
    "sorted_ = sorted_.explode('diff').drop_nulls()\n",
    "\n",
    "sorted_std = sorted_.group_by('user').agg(pl.col('diff').std().alias('std'))\n",
    "\n",
    "sorted_mean = sorted_.group_by('user').agg(pl.col('diff').mean().alias('mean'))\n",
    "\n",
    "sorted_comb = sorted_std.join(sorted_mean, on = \"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb45f2-3050-4320-84eb-a50e1c1dafcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join dataframes\n",
    "data_join1 = data1.join(sorted_comb, on = \"user\")\n",
    "\n",
    "data_join2 = data_join1.join(user_counts, on = \"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6fd84-70be-407a-ac68-3f48fea6647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get min and max timestamp data\n",
    "min_ = data_join2.select('timestamp').min().collect(streaming = True)\n",
    "\n",
    "max_ = data_join2.select('timestamp').max().collect(streaming = True)\n",
    "\n",
    "print(min_)\n",
    "print(max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f92f8bf-4b7b-47fc-9a65-270315c6b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time std plot\n",
    "(ggplot(data_join2.collect(streaming=True)) +\n",
    "    geom_point(aes(x = 'std', y = 'count')) +\n",
    "    theme(\n",
    "        figure_size = (16,9)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b6b1c-b8ca-4bd3-9846-43e603220aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time mean plot\n",
    "(ggplot(data_join2.collect(streaming=True)) +\n",
    "    geom_point(aes(x = 'mean', y = 'count')) +\n",
    "    theme(\n",
    "        figure_size = (16,9)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305f6cf-b59b-40ec-855a-64f2d7449a87",
   "metadata": {},
   "source": [
    "## Ben Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8a354-f279-4a58-b2c5-3b6ee32f3be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet File Writer\n",
    "# Providing folder path\n",
    "folder_path = \"<REPLACE WITH FILE FOLDER PATH>\"\n",
    "\n",
    "# Partquet file name\n",
    "parquet_file = \"combined_place_data.parquet\"\n",
    "\n",
    "# Getting csv_file names\n",
    "csv_files = glob.glob(os.path.join(folder_path, '**/*.csv'), recursive=True)\n",
    "\n",
    "# Create Schema\n",
    "schema = pa.schema([\n",
    "    pa.field(\"timestamp\", pa.string()),\n",
    "    pa.field(\"user\", pa.string()),\n",
    "    pa.field(\"coordinate\", pa.string()),\n",
    "    pa.field(\"pixel_color\", pa.string())\n",
    "])\n",
    "\n",
    "# Initializing writer\n",
    "writer = parquet.ParquetWriter(parquet_file, schema, compression='snappy')\n",
    "\n",
    "# Iterating through csv files\n",
    "for file in sorted(csv_files):\n",
    "    \n",
    "    print(\"reading\", file)\n",
    "    table = csv.read_csv(file)\n",
    "    # Casting table to schema\n",
    "    table = table.cast(schema)\n",
    "\n",
    "    print(\"writing\", file)\n",
    "    writer.write_table(table)\n",
    "    \n",
    "if writer:\n",
    "    writer.close()\n",
    "    \n",
    "print(f\"Combined CSVs to {parquet_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737043d-8e97-46cc-b9e8-35168f0d460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Parquet file and transform the data, maintain's lazyframe format\n",
    "print(\"Read parquet, cast datetime, and parse coordinates\")\n",
    "df = pl.scan_parquet('combined_place_data.parquet')\n",
    "df = df.with_columns(pl.col(\"timestamp\").str.strptime(pl.Datetime, '%Y-%m-%d %H:%M:%S%.f %Z').cast(pl.Datetime, strict=False))\n",
    "df = df.with_columns(\n",
    "    pl.col('coordinate').map_elements(parse_coordinate, return_dtype=pl.Object)\n",
    ")\n",
    "df = df.with_columns([\n",
    "    pl.col('coordinate').map_elements(lambda x: int(x.split(\",\")[0]), return_dtype=pl.Int32).alias('x'),\n",
    "    pl.col('coordinate').map_elements(lambda x: int(x.split(\",\")[1]), return_dtype=pl.Int32).alias('y')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de3846-d236-4380-b443-0407dd9a10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of pixels per unique user\n",
    "value_counts = df.select(\"user\").group_by(\"user\").agg(pl.col('user').count().alias('count')).sort('count', descending=True)\n",
    "value_counts = value_counts.with_columns(pl.col(\"count\").cast(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bbaf33-2194-41b4-aea6-40c1b2418cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pixels placed quantile\n",
    "value_counts.select(\"count\").quantile(quantile=.95).collect(streaming = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2f1d7-896a-4a9e-8afd-560838879dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index users with more than x number of pixels placed\n",
    "pbs_idx = value_counts.filter(pl.col(\"count\") >= 60)\n",
    "\n",
    "# Select users and data from the prior list\n",
    "pixels_placed = df.filter(pl.col('user').is_in(pbs_idx.select(\"user\").collect(streaming=True))).collect(streaming=True)\n",
    "\n",
    "# Filter down to top layer of pixels placed\n",
    "latest_coords = pixels_placed.group_by([\"x\", \"y\"]).agg(\n",
    "    pl.col('timestamp').arg_max().alias('idxmax'),\n",
    "    pl.col(\"pixel_color\").last().alias(\"latest_color\")\n",
    ")\n",
    "\n",
    "# Write parquet file with pixel location and color\n",
    "latest_coords.write_parquet(\"<REPLACE WITH FILE FOLDER PATH>.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae139d7-b7e9-4359-9125-25e98f18af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in parquet file created above and sanity check\n",
    "latest_coords = pd.read_parquet(\"latest_coords99.parquet\")\n",
    "latest_coords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16dc55-ca9c-46fb-b250-d96e5dad548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create r/Place Image\n",
    "plot = (ggplot(latest_coords, aes(x = \"x\", y = \"y\", color = \"latest_color\")) + \n",
    "    geom_point(shape = \"s\", size = .5) +\n",
    "    theme(figure_size=[30, 20]) +\n",
    "    scale_y_reverse() +\n",
    "    scale_color_identity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237beb1c-aced-438e-bc68-d0abab3d9642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Plot\n",
    "plot.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf61dff-67a9-48a3-b2e6-f74a6a4951c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Plot\n",
    "plot.save(limitsize=False, filename=\"<REPLACE WITH DESIRED FILE NAME AND DATATYPE>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
